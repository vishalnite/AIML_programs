{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01487512",
   "metadata": {},
   "source": [
    "## P6 - Q-Learning\n",
    "\n",
    "The code implements a Q-learning algorithm to find the shortest path in a grid-based environment with rewards and obstacles. The environment consists of an 11x11 grid, where certain cells have negative rewards (aisles and obstacles), one cell has a positive reward (goal), and the rest have default negative rewards. The Q-learning algorithm aims to learn a policy that maximizes the cumulative reward by updating the Q-values for each state-action pair iteratively. The Q-values are initialized to zero, and the algorithm explores the environment by taking actions (up, right, down, left) based on an epsilon-greedy policy. The training process involves updating Q-values using the temporal difference error and a learning rate. After training, the code outputs the learned Q-values and demonstrates the shortest path from a specified starting point (3,9) to the goal by following the actions with the highest Q-values at each step. The epsilon parameter controls the exploration-exploitation trade-off, and the discount factor determines the importance of future rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "115ba079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "actions = ['up', 'right', 'down', 'left']\n",
    "environment_rows = 11\n",
    "environment_columns = 11\n",
    "\n",
    "rewards = np.full((environment_rows, environment_columns), -100.)\n",
    "rewards[0, 5] = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771a45bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aisles depend on your environmnet rows and columns \n",
    "aisles = {\n",
    "    1: list(range(1, 10)),\n",
    "    2: [1, 7, 9],\n",
    "    3: list(range(1, 8)) + [9],\n",
    "    4: [3, 7],\n",
    "    5: list(range(11)),\n",
    "    6: [5],\n",
    "    7: list(range(1, 10)),\n",
    "    8: [3, 7],\n",
    "    9: list(range(11))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebcdcc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_index in range(1, environment_rows - 1):\n",
    "        for column_index in aisles[row_index]:\n",
    "            rewards[row_index, column_index] = -1.\n",
    "\n",
    "q_values = np.zeros((environment_rows, environment_columns, len(actions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c61f1bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_terminal_state(current_row_index, current_column_index):\n",
    "    return rewards[current_row_index, current_column_index] != -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "659cf041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_starting_location():\n",
    "    while True:\n",
    "        current_row_index, current_column_index = np.random.randint(\n",
    "            environment_rows), np.random.randint(environment_columns)\n",
    "        if not is_terminal_state(current_row_index, current_column_index):\n",
    "            return current_row_index, current_column_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5defeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_action(current_row_index, current_column_index, epsilon):\n",
    "    if np.random.random() < epsilon:\n",
    "        return np.argmax(q_values[current_row_index, current_column_index])\n",
    "    else:\n",
    "        return np.random.randint(len(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27955c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_location(current_row_index, current_column_index, action_index):\n",
    "    movement = {'up': (-1, 0), 'right': (0, 1),\n",
    "                'down': (1, 0), 'left': (0, -1)}\n",
    "    new_row_index = max(0, min(environment_rows - 1,\n",
    "                                current_row_index + movement[actions[action_index]][0]))\n",
    "    new_column_index = max(0, min(environment_columns - 1,\n",
    "                                   current_column_index + movement[actions[action_index]][1]))\n",
    "    return new_row_index, new_column_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ec4d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_path(start_row_index, start_column_index):\n",
    "    if is_terminal_state(start_row_index, start_column_index):\n",
    "        return []\n",
    "    else:\n",
    "        current_row_index, current_column_index = start_row_index, start_column_index\n",
    "        shortest_path = [[current_row_index, current_column_index]]\n",
    "\n",
    "        while not is_terminal_state(current_row_index, current_column_index):\n",
    "            action_index = get_next_action(\n",
    "                current_row_index, current_column_index, 1.)\n",
    "            current_row_index, current_column_index = get_next_location(\n",
    "                current_row_index, current_column_index, action_index)\n",
    "            shortest_path.append([current_row_index, current_column_index])\n",
    "\n",
    "        return shortest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b60051e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment:\n",
      "[[-100. -100. -100. -100. -100.  100. -100. -100. -100. -100. -100.]\n",
      " [-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.]\n",
      " [-100.   -1. -100. -100. -100. -100. -100.   -1. -100.   -1. -100.]\n",
      " [-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.   -1. -100.]\n",
      " [-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100. -100.]\n",
      " [  -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.]\n",
      " [-100. -100. -100. -100. -100.   -1. -100. -100. -100. -100. -100.]\n",
      " [-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.]\n",
      " [-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100. -100.]\n",
      " [  -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.]\n",
      " [-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.]]\n",
      "\n",
      "Training complete!\n",
      "\n",
      "Shortest path: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[3, 9], [2, 9], [1, 9], [1, 8], [1, 7], [1, 6], [1, 5], [0, 5]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = 0.9\n",
    "discount_factor = 0.9\n",
    "learning_rate = 0.9\n",
    "\n",
    "for episode in range(1000):\n",
    "    row_index, column_index = get_starting_location()\n",
    "\n",
    "    while not is_terminal_state(row_index, column_index):\n",
    "        action_index = get_next_action(row_index, column_index, epsilon)\n",
    "        old_row_index, old_column_index = row_index, column_index\n",
    "        row_index, column_index = get_next_location(\n",
    "            row_index, column_index, action_index)\n",
    "\n",
    "        reward = rewards[row_index, column_index]\n",
    "        old_q_value = q_values[old_row_index, old_column_index, action_index]\n",
    "        temporal_difference = reward + \\\n",
    "            (discount_factor *\n",
    "            np.max(q_values[row_index, column_index])) - old_q_value\n",
    "        new_q_value = old_q_value + (learning_rate * temporal_difference)\n",
    "        q_values[old_row_index, old_column_index, action_index] = new_q_value\n",
    "\n",
    "print('Environment:')\n",
    "print(rewards)\n",
    "print('\\nTraining complete!\\n')\n",
    "print('Shortest path: ')\n",
    "get_shortest_path(3,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eec4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
